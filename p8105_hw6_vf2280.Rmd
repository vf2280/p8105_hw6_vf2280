---
title: "Homework 6"
author: "Vasili Fokaidis"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include = FALSE}
library(tidyverse)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Read in data.

## Problem 1

Read in the data.

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv", na = c("", "NA", "Uknown")) %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>%
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>%
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with one city.

```{r}
baltimore_df = 
  homicide_df %>%
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex,
    data = baltimore_df,
    family = binomial()) %>%
  broom::tidy() %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(term, OR, starts_with("CI")) %>%
  knitr::kable(digits = 3)
```


Try this across cities.

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 
```


## Problem 2

Read in data.

```{r}
bth_wt = 
  read_csv("birthweight_data/birthweight.csv") %>%
  mutate(
    babysex = as.factor(babysex),
    mrace = as.factor(mrace),
    frace = as.factor(frace),
    bwt = bwt/453.592,
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("white", "black", "asian", "puerto_rican", "other", "unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), labels = c("white", "black", "asian", "puerto_rican", "other")),
    babysex = recode(babysex, `1` = 0L, `2` = 1L)
  )
```

To clean the data, I turned `babysex`, `frace`, and `mrace` into factors, I converted `bwt` from grams to pounds, and I converted `frace` and `mrace` values to the corresponding races. And, I recoded `babysex` into a dummy variable where 0 = Male, and 1 = Female.


Let's fit the model we care about (through backwards elimination)

```{r}
full_model = 
  lm(bwt ~ ., data = bth_wt)

step(full_model, direction = "backward", trace = TRUE)

full_model =
  step(full_model, direction = "backward", trace = FALSE)

full_model %>% summary()
```

Using backward elimination, the model was fitted using criterion based procedures (discrimination based on AIC values of various models). First, I developed a linear model containing all variables, then I ran the backward elimination with trace to evaluate the steps taken to deduce the final model. For example, the model without `wtgain` produced an AIC of -4403.92, and since this criterion based procedure aims for models with the lowest AIC, `wtgain` was removed, and so on. Finally, after many steps of this process, the model was produced.

Let's look at the result...

```{r}
 bth_wt %>%
  add_residuals(full_model) %>%
  add_predictions(full_model) %>%
  ggplot(aes(x = pred , y = resid)) +
  geom_point() +
  theme_bw()
```

The residuals are mostly well-behaved centering around 0. There is little deviation from the estimated regression line.

Compare your models. Make two others first.

```{r}
full_model %>% summary()

new_fit_0 = lm(bwt ~ blength + gaweeks, data = bth_wt)
summary(new_fit_0)

new_fit_1 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = bth_wt)
summary(new_fit_1)
```

Now cross validate using modelr.

```{r}
cv_df = 
  crossv_mc(bth_wt, 100)

cv_df = 
  cv_df %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df_1 = 
  cv_df %>%
    mutate(
      full_model = map(.x = train, ~ lm(bwt ~ ., data = .x)),
      new_fit_0 = map(.x = train, ~ lm(bwt ~ blength + gaweeks, data = .x )),
      new_fit_1 = map(.x = train, ~ lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))
    ) %>%
    mutate(
      rmse_full = map2(.x = full_model, .y = test, ~ rmse(model = .x, data = .y)),
      rmse_fit_0 = map2(.x = new_fit_0, .y = test, ~ rmse(model = .x, data = .y)),
      rmse_fit_1 = map2(.x = new_fit_1, .y = test, ~ rmse(model = .x, data = .y))
    )

```

What does this look like?

```{r}
cv_df_1 %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>%
  unnest() %>%
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  labs(
    title = "Residuals vs Fitted Values",
    y = "Residuals",
    x = "Fitted Values")
  
```

`fit_0` model shows high RMSEs compared to the `fit_1` and `full` model. The `full` model shows to have the lowest RMSEs making it one of the better models of the three. `fit_1` also shows low RMSEs, but this model is more complex and perhaps, harder to interpret. So, the `fit_1` model is better overall in terms of fit and interpretation.

Compute average RMSEs.

```{r}
cv_df_1 %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>%
  unnest() %>%
  group_by(model) %>%
  summarize(avg_rmse = mean(rmse)) %>%
  knitr::kable()
```

Comment on RMSE

## Problem 3

Read in data.

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Create bootstrap function. And, bootstrap 5000 times.

```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  tibble(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )
```


Run regression with `tmax` as response and `tmin` as predictor. And produce estimates of $\hat{r}^2$ and 
$\log(\hat{\beta}_0 * \hat{\beta}_1)$

```{r}
r_sq = 
  boot_straps %>%
  mutate(
    models = map(.x = strap_sample, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)
  ) %>%
  select(strap_number, results) %>%
  unnest(results) 

log_b0_b1 =
  boot_straps %>%
    mutate(
      models = map(.x = strap_sample, ~lm(tmax ~ tmin, data = .x)),
      results = map(models, broom::tidy)
    ) %>%
    unnest(results) %>%
    select(term, estimate) %>%
    pivot_wider(
      names_from = term,
      values_from = estimate
    ) %>%
    unnest() %>%
    rename(
      intercept = `(Intercept)`
    ) %>%
    summarize(
      log_b0_b1 = log(intercept/tmin),
      strap_number = c(1:5000)
    )

boot_results =
  right_join(x = r_sq, y = log_b0_b1, by = "strap_number", all = TRUE)

boot_results
```

Plot distributions of estimates.

```{r}
par(mfrow = c(1, 2))

boot_results %>%
  ggplot(aes(x = r.squared)) +
  geom_density()

boot_results %>%
  ggplot(aes(x = log_b0_b1)) +
  geom_density()
```

The distribution of the `r.squared` values shows heavy tails. It also indicates a prominent peak at roughly 0.915 indicating that the data are close to the fitted regression line.

As for `log_b0_1`, the distribution shows heavy tails as well with a peak around roughly 1.95. This shows that the log-transformed interaction indicates that for every 1 degree increase in tmin, there is a 1.95 increase in tmax.

Confidence intervals for $\hat{r}^2$ and $\log(\hat{\beta}_0 * \hat{\beta}_1)$!

```{r}
boot_results %>%
  select(r.squared, log_b0_b1) %>%
  pivot_longer(
    everything(),
    names_to = "term",
    values_to = "estimate"
  ) %>%
  group_by(term) %>%
  summarize(
    ci_lwr = quantile(estimate, 0.025),
    ci_upr = quantile(estimate, 0.975)
  ) %>%
  knitr::kable()

```

